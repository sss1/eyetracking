- Plot histograms of missing data proportions (before and after imputation?)
  - How much data is missing per trial
  - Using various discarding thresholds, how many trials are removed per participant?

- Tune parameters until results look reasonable
    - sigma2 = 100 ** 2 seems to work reasonably well
- Figure out how to handle missing eye-tracker data
  - Options:
    1) Assume each state emits NaN with equal probability - what to do for inattentive state?
    2) Remove nan time points, and treat segments separately - easy but wrong
    3) Categorize as new state - what is the transition prob. from this state?
- Add inattentive state
  - What is the distribution? Uniform over the screen?

...

- Implement EM (Baum-Welch) to improve transition matrices, covariance, etc.


12/5/17 Meeting Notes

<Missing Data>
Less than 10 frames - can definitely impute
--- Figure out boundary (histogram) ---
More than half missing, delete trial
More than half trials missing, delete kid

Trial start - estimate from data

More elaborate transition matrix, incorporating distances between objects (maybe hard-coded step-function)

Things we might want to test:
- How often are we in the target state?
  - How does this differ between all-same and all-different conditions?
- How often do we start at the target state?
  - Does this differ between all-same and all-different conditions?
- How often do we end at the target state?
  - How does this differ between memory-correct and memory-incorrect trials?
- How often do we switch targets?
  - This is highly sensitive to parameters
- How often do we revert to target after being distracted?

12/15/17 Meeting Notes
- Look at data quality of: 
  - Blinky data (does this improve early-trial performance?)
  - Supervised data

Publication Notes

- CogSci paper on cognitive modeling of 
  - Compare HMM vs. other cognitive models of visual object tracking
    - Regular or supervised TrackIt?
      - Probably supervised, because then we can use decoding accuracy to
        measure performance
- CogSci paper
  - Validate model on supervised TrackIt
  - Reaffirm TrackIt behavioral results
    - Same versus different conditions (on target more often in same?)
    - Any relationship between eye-tracking and error types?
      - e.g., can we use eye-tracking to bound spatial resolution error?

